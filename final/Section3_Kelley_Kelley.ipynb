{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelley Kelley\n",
    "## Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "Our inputs are vectors of length 5.\n",
    "So layer 1 will be 5x2.\n",
    "Layer 2 will be 2x3.\n",
    "And our projection layer will be 3x2.\n",
    "1x5 * 5x2 * 2x3 * 3x2 = 1x2 which is in our output space.\n",
    "So we need to train 5 * 2 + 2 * 3 + 3 * 2 weights = <mark style=\"background-color: yellow !important; font-weight:bold\"> 22 </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "In a neural language model words are represented as vectors. These vectors are called embeddings and basically it takes a word and transforms it into a sequence of numbers and that is how they are represented in neural language models.\n",
    "\n",
    "These representations can be produced using skip-gram. Skip-gram takes sentences and then produces embeddings for the current word by doing logistic regression using words close to it as positive examples and words far away from the target as negative examples, trying to maximize the target word's similarity to close words, and minimize the target word's similarity to farther away words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "a. The number of matrices trained will be the vocab size ^ how many tags you have\n",
    "\n",
    "b. The inputs to each layer are the embeddings of the word and the previous hidden layer combined with the transition\n",
    "\n",
    "c. Combine the weighted sum of the inputs and the previous layer and apply a non linearity to them.\n",
    "\n",
    "d. The output layer takes the values from the hidden layer and puts them through a softmax in order to get the probability for each tag\n",
    "\n",
    "e. Pick the tag with the highest probability for the last word, then back propogate filling in what tags led to that tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "\n",
    "<mark style=\"background-color: yellow !important; font-weight:bold\"> c. </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "\n",
    "<mark style=\"background-color: yellow !important; font-weight:bold\"> False </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quetion 6:\n",
    "\n",
    "<mark style=\"background-color: yellow !important; font-weight:bold\"> independent </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citations:\n",
    "\n",
    "Felix's NLP Slides 16, 17, 18, 22"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
